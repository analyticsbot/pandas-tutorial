{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 28: Advanced Rolling Operations and GroupBy Basics\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Advanced rolling window operations with custom functions\n",
    "- Using Numba for performance optimization\n",
    "- Weighted rolling windows\n",
    "- Introduction to GroupBy operations\n",
    "\n",
    "##### Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plotting style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Make plots appear in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Rolling Apply with Custom Functions\n",
    "\n",
    "The `apply()` function allows you to perform generic rolling computations with custom functions. Let's create a sample time series first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series for rolling window examples\n",
    "s = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "s = s.cumsum()\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a custom function to compute the mean absolute deviation on a rolling basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad(x):\n",
    "    return np.fabs(x - x.mean()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom function to a rolling window\n",
    "s.rolling(window=60).apply(mad, raw=True).plot(style='k', figsize=(10, 6), \n",
    "                                             title='Rolling Mean Absolute Deviation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Using Numba for Performance Optimization\n",
    "\n",
    "Pandas' `apply()` function can leverage Numba for performance optimization. Numba is a JIT (Just-In-Time) compiler that can significantly speed up Python functions, especially for numerical computations.\n",
    "\n",
    "To use Numba, you need to specify `engine='numba'` and set `raw=True`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large Series for performance comparison\n",
    "data = pd.Series(range(1_000_000))\n",
    "roll = data.rolling(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function for rolling apply\n",
    "def f(x):\n",
    "    return np.sum(x) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: Numba vs Cython\n",
    "# Note: First run with Numba will be slower due to compilation overhead\n",
    "%timeit -r 1 -n 1 roll.apply(f, engine='numba', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second run with Numba will be faster as the function is cached\n",
    "%timeit roll.apply(f, engine='numba', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Cython engine\n",
    "%timeit roll.apply(f, engine='cython', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Weighted Rolling Windows\n",
    "\n",
    "You can create weighted rolling windows by passing the `win_type` parameter to the `rolling()` method. The weights used in the window are specified by the `win_type` keyword.\n",
    "\n",
    "Let's create a small Series to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small Series for weighted rolling window examples\n",
    "ser = pd.Series(np.random.randn(10), \n",
    "               index=pd.date_range('1/1/2000', periods=10))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a triangular window\n",
    "ser.rolling(window=5, win_type='triang').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare different window types visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger Series for visualization\n",
    "larger_ser = pd.Series(np.random.randn(100).cumsum(), \n",
    "                      index=pd.date_range('1/1/2000', periods=100))\n",
    "\n",
    "# Create a figure with multiple window types\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "window_types = ['boxcar', 'triang', 'blackman', 'hamming', 'bartlett', 'bohman']\n",
    "\n",
    "# Plot original data on all subplots\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    larger_ser.plot(ax=ax, alpha=0.5, label='Original', legend=True)\n",
    "    if i < len(window_types):\n",
    "        # Apply the window type\n",
    "        win_type = window_types[i]\n",
    "        larger_ser.rolling(window=20, win_type=win_type).mean().plot(\n",
    "            ax=ax, label=f'{win_type} window', legend=True)\n",
    "        ax.set_title(f'Window Type: {win_type}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Introduction to GroupBy Operations\n",
    "\n",
    "GroupBy operations allow you to split your data into groups, apply a function to each group independently, and then combine the results. This is often referred to as the \"split-apply-combine\" pattern.\n",
    "\n",
    "Let's start with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Series with repeating indices\n",
    "s = pd.Series([1, 2, 3, 10, 20, 30], index=[1, 2, 3, 1, 2, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by index\n",
    "grouped = s.groupby(level=0)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first value in each group\n",
    "grouped.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last value in each group\n",
    "grouped.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the values in each group\n",
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 GroupBy Sorting\n",
    "\n",
    "By default, the group keys are sorted during the groupby operation. You can pass `sort=False` for potential speedups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for groupby examples\n",
    "df2 = pd.DataFrame({'X': ['B', 'B', 'A', 'A'], 'Y': [1, 2, 3, 4]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default sorting (alphabetical)\n",
    "df2.groupby(['X']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No sorting (order of appearance)\n",
    "df2.groupby(['X'], sort=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupBy will preserve the order in which observations are sorted within each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another DataFrame for groupby examples\n",
    "df3 = pd.DataFrame({'X': ['A', 'B', 'A', 'B'], 'Y': [1, 4, 3, 2]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get group 'A' - order is preserved\n",
    "df3.groupby(['X']).get_group('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get group 'B' - order is preserved\n",
    "df3.groupby(['X']).get_group('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 GroupBy Object Attributes\n",
    "\n",
    "The `groups` attribute is a dict whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for more complex groupby examples\n",
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n",
    "                  'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "                  'C': np.random.randn(8),\n",
    "                  'D': np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the groups when grouping by column 'A'\n",
    "df.groupby('A').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to identify vowels and consonants\n",
    "def get_letter_type(letter):\n",
    "    if letter in 'aeiou':\n",
    "        return 'vowel'\n",
    "    else:\n",
    "        return 'consonant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by a function along axis=1 (columns)\n",
    "df.groupby(get_letter_type, axis=1).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "grouped = df.groupby(['A', 'B'])\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of groups\n",
    "len(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a different DataFrame with a DatetimeIndex to demonstrate more GroupBy functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with a DatetimeIndex\n",
    "df = pd.DataFrame({\n",
    "    'height': np.random.normal(loc=60, scale=10, size=8),\n",
    "    'weight': np.random.normal(loc=160, scale=15, size=8),\n",
    "    'gender': np.random.choice(['male', 'female'], size=8)\n",
    "}, index=pd.date_range('1/1/2000', periods=8))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "1. Advanced rolling operations with custom functions using `apply()`\n",
    "2. Performance optimization with Numba for rolling operations\n",
    "3. Weighted rolling windows with various window types\n",
    "4. Introduction to GroupBy operations, including:\n",
    "   - Basic groupby functionality\n",
    "   - GroupBy sorting options\n",
    "   - GroupBy object attributes\n",
    "\n",
    "These techniques provide powerful tools for time series analysis and data aggregation in pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}