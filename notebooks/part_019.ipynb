{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 19: Advanced Concatenation and Merging in Pandas\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Concatenating with mixed dimensions\n",
    "- Using group keys in concatenation\n",
    "- Joining multiple DataFrames\n",
    "- Merging values within Series or DataFrame columns\n",
    "- Timeseries friendly merging\n",
    "\n",
    "##### Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Concatenating with Mixed Dimensions\n",
    "\n",
    "You can concatenate a mix of Series and DataFrame objects. The Series will be transformed to DataFrame with the column name as the name of the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D1', 'D2', 'D3']\n",
    "}, index=[0, 1, 2, 3])\n",
    "\n",
    "# Create a Series\n",
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')\n",
    "\n",
    "# Concatenate DataFrame and Series\n",
    "result = pd.concat([df1, s1], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If unnamed Series are passed they will be numbered consecutively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an unnamed Series\n",
    "s2 = pd.Series(['_0', '_1', '_2', '_3'])\n",
    "\n",
    "# Concatenate DataFrame and multiple unnamed Series\n",
    "result = pd.concat([df1, s2, s2, s2], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `ignore_index=True` will drop all name references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with ignore_index=True\n",
    "result = pd.concat([df1, s1], axis=1, ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. More Concatenating with Group Keys\n",
    "\n",
    "A fairly common use of the keys argument is to override the column names when creating a new DataFrame based on existing Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series with and without names\n",
    "s3 = pd.Series([0, 1, 2, 3], name='foo')\n",
    "s4 = pd.Series([0, 1, 2, 3])\n",
    "s5 = pd.Series([0, 1, 4, 5])\n",
    "\n",
    "# Default behavior inherits Series names\n",
    "pd.concat([s3, s4, s5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override column names with keys\n",
    "pd.concat([s3, s4, s5], axis=1, keys=['red', 'blue', 'yellow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some sample DataFrames to demonstrate keys with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional sample DataFrames\n",
    "df2 = pd.DataFrame({\n",
    "    'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "    'D': ['D4', 'D5', 'D6', 'D7']\n",
    "}, index=[4, 5, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "    'D': ['D8', 'D9', 'D10', 'D11']\n",
    "}, index=[8, 9, 10, 11])\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "\n",
    "# Concatenate with keys\n",
    "result = pd.concat(frames, keys=['x', 'y', 'z'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a dict to concat in which case the dict keys will be used for the keys argument (unless other keys are specified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of DataFrames\n",
    "pieces = {'x': df1, 'y': df2, 'z': df3}\n",
    "\n",
    "# Concatenate using dict keys\n",
    "result = pd.concat(pieces)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify different keys\n",
    "result = pd.concat(pieces, keys=['z', 'y'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultiIndex created has levels that are constructed from the passed keys and the index of the DataFrame pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the index levels\n",
    "result.index.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to specify other levels, you can do so using the levels argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify custom levels\n",
    "result = pd.concat(pieces, keys=['x', 'y', 'z'],\n",
    "                  levels=[['z', 'y', 'x', 'w']],\n",
    "                  names=['group_key'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the custom levels\n",
    "result.index.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Joining Multiple DataFrames\n",
    "\n",
    "A list or tuple of DataFrames can also be passed to join() to join them together on their indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with index\n",
    "left = pd.DataFrame({'v': [1, 2, 3]}, index=['K0', 'K1', 'K2'])\n",
    "right = pd.DataFrame({'v': [4, 5, 6]}, index=['K0', 'K0', 'K3'])\n",
    "right2 = pd.DataFrame({'v': [7, 8, 9]}, index=['K1', 'K1', 'K2'])\n",
    "\n",
    "# Join multiple DataFrames\n",
    "result = left.join([right, right2])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Merging Together Values within Series or DataFrame Columns\n",
    "\n",
    "Another fairly common situation is to have two like-indexed (or similarly indexed) Series or DataFrame objects and wanting to \"patch\" values in one object from values for matching indices in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with NaN values\n",
    "df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan],\n",
    "                   [np.nan, 7., np.nan]])\n",
    "df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5., 1.6, 4]],\n",
    "                   index=[1, 2])\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "display(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, use the `combine_first()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine values, taking values from df2 only when missing in df1\n",
    "result = df1.combine_first(df2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this method only takes values from the right DataFrame if they are missing in the left DataFrame. A related method, `update()`, alters non-NA values in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df1 to demonstrate update\n",
    "df1_copy = df1.copy()\n",
    "print(\"Before update:\")\n",
    "display(df1_copy)\n",
    "\n",
    "# Update df1 with values from df2\n",
    "df1_copy.update(df2)\n",
    "\n",
    "print(\"\\nAfter update:\")\n",
    "display(df1_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Timeseries Friendly Merging\n",
    "\n",
    "### 5.1 Merging Ordered Data\n",
    "\n",
    "A `merge_ordered()` function allows combining time series and other ordered data. In particular it has an optional `fill_method` keyword to fill/interpolate missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames for ordered merge\n",
    "left = pd.DataFrame({'k': ['K0', 'K1', 'K1', 'K2'],\n",
    "                     'lv': [1, 2, 3, 4],\n",
    "                     's': ['a', 'b', 'c', 'd']})\n",
    "\n",
    "right = pd.DataFrame({'k': ['K1', 'K2', 'K4'],\n",
    "                      'rv': [1, 2, 3]})\n",
    "\n",
    "# Merge ordered with forward fill\n",
    "pd.merge_ordered(left, right, fill_method='ffill', left_by='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Merging Asof\n",
    "\n",
    "A `merge_asof()` is similar to an ordered left-join except that we match on nearest key rather than equal keys. For each row in the left DataFrame, we select the last row in the right DataFrame whose on key is less than the left's key. Both DataFrames must be sorted by the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames for asof merge (trades and quotes)\n",
    "trades = pd.DataFrame({\n",
    "    'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.038',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.048']),\n",
    "    'ticker': ['MSFT', 'MSFT', 'GOOG', 'GOOG', 'AAPL'],\n",
    "    'price': [51.95, 51.95, 720.77, 720.92, 98.00],\n",
    "    'quantity': [75, 155, 100, 100, 100]\n",
    "})\n",
    "\n",
    "quotes = pd.DataFrame({\n",
    "    'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.030',\n",
    "                           '20160525 13:30:00.041',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.049',\n",
    "                           '20160525 13:30:00.072',\n",
    "                           '20160525 13:30:00.075']),\n",
    "    'ticker': ['GOOG', 'MSFT', 'MSFT', 'MSFT', 'GOOG', 'AAPL', 'GOOG', 'MSFT'],\n",
    "    'bid': [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n",
    "    'ask': [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03]\n",
    "})\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Trades:\")\n",
    "display(trades)\n",
    "print(\"\\nQuotes:\")\n",
    "display(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an asof merge\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do an asof merge with a tolerance, meaning we only merge values within a certain time difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof merge with tolerance\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker', tolerance=pd.Timedelta('2ms'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the direction parameter to control whether the merge should look for values forward, backward, or nearest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof merge with direction='forward'\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker', direction='forward')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}