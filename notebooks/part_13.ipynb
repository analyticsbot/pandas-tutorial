{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13: Advanced Excel and HDF5 Operations in Pandas\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Working with MultiIndex in Excel files\n",
    "- Parsing specific columns in Excel\n",
    "- Parsing dates and cell converters\n",
    "- HDF5 operations and iterators\n",
    "\n",
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Excel Operations with MultiIndex\n",
    "\n",
    "### 1.1 MultiIndex in Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with MultiIndex in both rows and columns\n",
    "df = pd.DataFrame({'a': [1, 2, 3, 4], 'b': [5, 6, 7, 8]},\n",
    "                 index=pd.MultiIndex.from_product([['a', 'b'], ['c', 'd']],\n",
    "                                                 names=['lvl1', 'lvl2']))\n",
    "\n",
    "# Set MultiIndex for columns\n",
    "df.columns = pd.MultiIndex.from_product([['a'], ['b', 'd']],\n",
    "                                       names=['c1', 'c2'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would write to an Excel file and then read it back\n",
    "'''\n",
    "df.to_excel('path_to_file.xlsx')\n",
    "df = pd.read_excel('path_to_file.xlsx', index_col=[0, 1], header=[0, 1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parsing Specific Columns in Excel\n",
    "\n",
    "The `usecols` parameter allows you to specify a subset of columns to parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are code examples - you would need an actual Excel file to run them\n",
    "'''\n",
    "# Specify columns by index (list of integers)\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', usecols=[0, 2, 3])\n",
    "\n",
    "# Specify columns as a string with column letters\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', usecols='A,C:E')\n",
    "\n",
    "# Specify columns by name\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', usecols=['foo', 'bar'])\n",
    "\n",
    "# Use a callable function to select columns\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', usecols=lambda x: x.isalpha())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parsing Dates\n",
    "\n",
    "Datetime-like values are normally automatically converted to the appropriate dtype when reading the Excel file. But if you have a column of strings that look like dates (but are not actually formatted as dates in Excel), you can use the `parse_dates` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', parse_dates=['date_strings'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cell Converters\n",
    "\n",
    "It is possible to transform the contents of Excel cells via the `converters` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Convert a column to boolean\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', converters={'MyBools': bool})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Custom converter function\n",
    "def cfun(x):\n",
    "    return int(x) if x else -1\n",
    "\n",
    "pd.read_excel('path_to_file.xls', 'Sheet1', converters={'MyInts': cfun})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dtype Specifications\n",
    "\n",
    "As an alternative to converters, the type for an entire column can be specified using the `dtype` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pd.read_excel('path_to_file.xls', dtype={'MyInts': 'int64', 'MyText': str})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HDF5 Operations\n",
    "\n",
    "### 6.1 Using Iterator with HDF5\n",
    "\n",
    "You can pass `iterator=True` or `chunksize=number_in_a_chunk` to `select` and `select_as_multiple` to return an iterator on the results. The default is 50,000 rows returned in a chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Example with HDFStore\n",
    "store = pd.HDFStore('store.h5')\n",
    "\n",
    "# Iterate through chunks of 3 rows\n",
    "for df in store.select('df', chunksize=3):\n",
    "    print(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the iterator with `read_hdf` which will open, then automatically close the store when finished iterating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for df in pd.read_hdf('store.h5', 'df', chunksize=3):\n",
    "    print(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Creating Equal Sized Chunks with Queries\n",
    "\n",
    "The `chunksize` keyword applies to the source rows. If you are doing a query, then the chunksize will subdivide the total rows in the table and the query applied, returning an iterator on potentially unequal sized chunks. Here is a recipe for generating a query and using it to create equal sized return chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create a sample DataFrame\n",
    "dfeq = pd.DataFrame({'number': np.arange(1, 11)})\n",
    "dfeq\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Store the DataFrame in HDF5\n",
    "store.append('dfeq', dfeq, data_columns=['number'])\n",
    "\n",
    "# Function to create chunks of a list\n",
    "def chunks(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "# Define values to query\n",
    "evens = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Get coordinates for the query\n",
    "coordinates = store.select_as_coordinates('dfeq', 'number=evens')\n",
    "\n",
    "# Process in chunks of 2\n",
    "for c in chunks(coordinates, 2):\n",
    "    print(store.select('dfeq', where=c))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Advanced Queries - Select a Single Column\n",
    "\n",
    "To retrieve a single indexable or data column, use the method `select_column`. This will enable you to get the index very quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Select just the index column\n",
    "store.select_column('df_dc', 'index')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
