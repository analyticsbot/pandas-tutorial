{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Tutorial - Part 35\n",
    "\n",
    "This notebook covers:\n",
    "- Performance considerations with pandas.eval()\n",
    "- Scaling to large datasets\n",
    "- Handling NaN, Integer NA values, and NA type promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Considerations with pandas.eval()\n",
    "\n",
    "Continuing from Part 34, let's explore more performance considerations with pandas.eval()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use eval()\n",
    "\n",
    "Operations with smallish objects (around 15k-20k rows) are often faster using plain Python rather than `eval()`. The real performance benefits of `eval()` are seen with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small DataFrames\n",
    "small_df1 = pd.DataFrame(np.random.randn(1000, 3))\n",
    "small_df2 = pd.DataFrame(np.random.randn(1000, 3))\n",
    "\n",
    "# Create large DataFrames\n",
    "large_df1 = pd.DataFrame(np.random.randn(50000, 3))\n",
    "large_df2 = pd.DataFrame(np.random.randn(50000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance for small DataFrames\n",
    "start = time.time()\n",
    "result1 = small_df1 + small_df2\n",
    "end = time.time()\n",
    "print(f\"Small DataFrame - Regular Python: {end - start:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "result2 = pd.eval('small_df1 + small_df2')\n",
    "end = time.time()\n",
    "print(f\"Small DataFrame - eval(): {end - start:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance for large DataFrames\n",
    "start = time.time()\n",
    "result3 = large_df1 + large_df2\n",
    "end = time.time()\n",
    "print(f\"Large DataFrame - Regular Python: {end - start:.6f} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "result4 = pd.eval('large_df1 + large_df2')\n",
    "end = time.time()\n",
    "print(f\"Large DataFrame - eval(): {end - start:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Details Regarding Expression Evaluation\n",
    "\n",
    "There are some technical details to be aware of when using `eval()`:\n",
    "\n",
    "1. Expressions that would result in an object dtype or involve datetime operations (because of NaT) must be evaluated in Python space.\n",
    "2. String comparisons must be evaluated in Python space.\n",
    "3. The numeric part of a comparison (e.g., `nums == 1`) will be evaluated by numexpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with strings and numbers\n",
    "df = pd.DataFrame({\n",
    "    'strings': np.repeat(list('cba'), 3),\n",
    "    'nums': np.repeat(range(3), 3)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with a string comparison and a numeric comparison\n",
    "df.query('strings == \"a\" and nums == 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the string comparison (`strings == \"a\"`) is evaluated in Python space, while the numeric comparison (`nums == 1`) is evaluated by numexpr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to Large Datasets\n",
    "\n",
    "Pandas provides data structures for in-memory analytics, which makes using pandas to analyze datasets that are larger than memory somewhat tricky. Here are some recommendations for scaling your analysis to larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Less Data\n",
    "\n",
    "When working with large datasets, it's often beneficial to load only the columns you need rather than the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading specific columns from a CSV file\n",
    "# This is just an example - adjust the file path and column names as needed\n",
    "# df = pd.read_csv('large_file.csv', usecols=['timestamp', 'id', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Chunking\n",
    "\n",
    "For very large files, you can process the data in chunks rather than loading it all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing a large CSV file in chunks\n",
    "# This is just an example - adjust the file path as needed\n",
    "\"\"\"\n",
    "chunk_size = 10000\n",
    "results = []\n",
    "\n",
    "for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):\n",
    "    # Process each chunk\n",
    "    processed = chunk.groupby('column_name').mean()\n",
    "    results.append(processed)\n",
    "\n",
    "# Combine the results\n",
    "combined_results = pd.concat(results)\n",
    "final_result = combined_results.groupby(level=0).mean()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN, Integer NA Values, and NA Type Promotions\n",
    "\n",
    "Pandas has a specific way of handling missing values (NA values) which is important to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of NA Representation\n",
    "\n",
    "Pandas uses the special value NaN (Not-A-Number) as the NA value for most data types. There are API functions `isna` and `notna` which can be used across the dtypes to detect NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with some NaN values\n",
    "s = pd.Series([1, 2, np.nan, 4, 5])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect NA values\n",
    "pd.isna(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect non-NA values\n",
    "pd.notna(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support for Integer NA\n",
    "\n",
    "One limitation of using NaN as the NA value is the inability to represent NAs in integer arrays. When you introduce NAs into an integer Series, it gets converted to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an integer Series\n",
    "s = pd.Series([1, 2, 3, 4, 5], index=list('abcde'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtype\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex to introduce NAs\n",
    "s2 = s.reindex(['a', 'b', 'c', 'f', 'u'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtype after reindexing\n",
    "s2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nullable Integer Data Types\n",
    "\n",
    "If you need to represent integers with possibly missing values, use one of the nullable-integer extension dtypes provided by pandas:\n",
    "- Int8Dtype\n",
    "- Int16Dtype\n",
    "- Int32Dtype\n",
    "- Int64Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an integer Series with a nullable integer dtype\n",
    "s_int = pd.Series([1, 2, 3, 4, 5], index=list('abcde'), dtype=pd.Int64Dtype())\n",
    "s_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtype\n",
    "s_int.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex to introduce NAs\n",
    "s2_int = s_int.reindex(['a', 'b', 'c', 'f', 'u'])\n",
    "s2_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtype after reindexing\n",
    "s2_int.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NA Type Promotions\n",
    "\n",
    "When introducing NAs into an existing Series or DataFrame via reindex() or some other means, boolean and integer types will be promoted to a different dtype in order to store the NAs. The promotions are summarized in this table:\n",
    "\n",
    "| Typeclass | Promotion dtype for storing NAs |\n",
    "|-----------|--------------------------------|\n",
    "| floating  | no change                      |\n",
    "| object    | no change                      |\n",
    "| integer   | cast to float64                |\n",
    "| boolean   | cast to object                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of boolean type promotion\n",
    "bool_series = pd.Series([True, False, True], index=['a', 'b', 'c'])\n",
    "print(f\"Original dtype: {bool_series.dtype}\")\n",
    "\n",
    "# Reindex to introduce NAs\n",
    "bool_series2 = bool_series.reindex(['a', 'b', 'c', 'd'])\n",
    "print(f\"Reindexed dtype: {bool_series2.dtype}\")\n",
    "bool_series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "1. Performance considerations with pandas.eval(), including when to use it and technical details about expression evaluation\n",
    "\n",
    "2. Strategies for scaling to large datasets, such as loading less data and using chunking\n",
    "\n",
    "3. Handling of NaN, Integer NA values, and NA type promotions in pandas, including:\n",
    "   - The choice of NA representation\n",
    "   - Support for integer NA values using nullable integer data types\n",
    "   - Type promotions that occur when introducing NAs into different data types\n",
    "\n",
    "These concepts are important for efficient data manipulation and analysis with pandas, especially when working with large datasets or dealing with missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
