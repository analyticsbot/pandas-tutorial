{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 14: Advanced HDF5 and Stata Operations in Pandas\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Advanced HDF5 query operations\n",
    "- Working with coordinates in HDF5\n",
    "- Multiple table queries\n",
    "- Working with Stata files\n",
    "\n",
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced HDF5 Operations\n",
    "\n",
    "### 1.1 Selecting Coordinates\n",
    "\n",
    "Sometimes you want to get the coordinates (index locations) of your query. This returns an Int64Index of the resulting locations. These coordinates can also be passed to subsequent where operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create a sample DataFrame\n",
    "df_coord = pd.DataFrame(np.random.randn(1000, 2),\n",
    "                       index=pd.date_range('20000101', periods=1000))\n",
    "\n",
    "# Store the DataFrame\n",
    "store = pd.HDFStore('store.h5')\n",
    "store.append('df_coord', df_coord)\n",
    "\n",
    "# Select coordinates where index is greater than a specific date\n",
    "c = store.select_as_coordinates('df_coord', 'index > 20020101')\n",
    "c\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Use the coordinates to select data\n",
    "store.select('df_coord', where=c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Selecting Using a Where Mask\n",
    "\n",
    "Sometimes your query can involve creating a list of rows to select. Usually this mask would be a resulting index from an indexing operation. This example selects the months of a datetimeindex which are 5 (May)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create a sample DataFrame\n",
    "df_mask = pd.DataFrame(np.random.randn(1000, 2),\n",
    "                      index=pd.date_range('20000101', periods=1000))\n",
    "\n",
    "# Store the DataFrame\n",
    "store.append('df_mask', df_mask)\n",
    "\n",
    "# Get the index column\n",
    "c = store.select_column('df_mask', 'index')\n",
    "\n",
    "# Create a mask for May months\n",
    "where = c[pd.DatetimeIndex(c).month == 5].index\n",
    "\n",
    "# Select using the mask\n",
    "store.select('df_mask', where=where)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Storer Object\n",
    "\n",
    "If you want to inspect the stored object, retrieve via `get_storer`. You could use this programmatically to say get the number of rows in an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "store.get_storer('df_dc').nrows\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Multiple Table Queries\n",
    "\n",
    "The methods `append_to_multiple` and `select_as_multiple` can perform appending/selecting from multiple tables at once. The idea is to have one table (call it the selector table) that you index most/all of the columns, and perform your queries. The other table(s) are data tables with an index matching the selector table's index. You can then perform a very fast query on the selector table, yet get lots of data back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Stata Files\n",
    "\n",
    "### 2.1 Reading Stata Files\n",
    "\n",
    "Pandas provides the `read_stata` function to read Stata data files (.dta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Read a Stata file\n",
    "df = pd.read_stata('stata.dta')\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Reading Stata Files in Chunks\n",
    "\n",
    "Specifying a `chunksize` yields a StataReader instance that can be used to read `chunksize` lines from the file at a time. The StataReader object can be used as an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Read a Stata file in chunks\n",
    "reader = pd.read_stata('stata.dta', chunksize=3)\n",
    "\n",
    "for df in reader:\n",
    "    print(df.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more fine-grained control, use `iterator=True` and specify `chunksize` with each call to `read()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "reader = pd.read_stata('stata.dta', iterator=True)\n",
    "\n",
    "chunk1 = reader.read(5)\n",
    "chunk2 = reader.read(5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Handling Categorical Data in Stata Files\n",
    "\n",
    "Categorical data can be exported to Stata data files as value labeled data. The exported data consists of the underlying category codes as integer data values and the categories as value labels. Stata does not have an explicit equivalent to a Categorical and information about whether the variable is ordered is lost when exporting.\n",
    "\n",
    "Labeled data can similarly be imported from Stata data files as Categorical variables using the keyword argument `convert_categoricals` (True by default). The keyword argument `order_categoricals` (True by default) determines whether imported Categorical variables are ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Import with categorical data\n",
    "df_cat = pd.read_stata('stata.dta', convert_categoricals=True, order_categoricals=True)\n",
    "\n",
    "# Import without converting to categorical\n",
    "df_no_cat = pd.read_stata('stata.dta', convert_categoricals=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Handling Missing Values in Stata Files\n",
    "\n",
    "The parameter `convert_missing` indicates whether missing value representations in Stata should be preserved. If False (the default), missing values are represented as np.nan. If True, missing values are represented using StataMissingValue objects, and columns containing missing values will have object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Import with default missing value handling (convert to np.nan)\n",
    "df_default = pd.read_stata('stata.dta')\n",
    "\n",
    "# Import preserving Stata missing value representation\n",
    "df_missing = pd.read_stata('stata.dta', convert_missing=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data Type Preservation\n",
    "\n",
    "Setting `preserve_dtypes=False` will upcast to the standard pandas data types: int64 for all integer types and float64 for floating point data. By default, the Stata data types are preserved when importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Import preserving Stata data types\n",
    "df_preserve = pd.read_stata('stata.dta')\n",
    "\n",
    "# Import with standard pandas data types\n",
    "df_standard = pd.read_stata('stata.dta', preserve_dtypes=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
