{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Tutorial - Part 39\n",
    "\n",
    "This notebook covers:\n",
    "- Working with STATA files\n",
    "- Advanced data manipulation with pandas.concat\n",
    "- Creating dummy variables with get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with STATA Files\n",
    "\n",
    "Pandas provides functionality to read and write STATA files, which are commonly used in statistical analysis, particularly in economics and social sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading STATA Files\n",
    "\n",
    "The `read_stata()` function allows you to read STATA files into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of reading a STATA file (commented out as it requires a .dta file)\n",
    "\"\"\"\n",
    "# Read a STATA file\n",
    "df_stata = pd.read_stata('filename.dta')\n",
    "df_stata.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameters for read_stata()\n",
    "\n",
    "The `read_stata()` function offers several parameters to customize how data is read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with various parameters (commented out as it requires a .dta file)\n",
    "\"\"\"\n",
    "# Read a STATA file with specific options\n",
    "df_stata = pd.read_stata(\n",
    "    'filename.dta',\n",
    "    convert_dates=True,           # Convert date variables to DataFrame time values\n",
    "    convert_categoricals=True,    # Convert columns to Categorical/Factor variables\n",
    "    index_col='id',               # Column to set as index\n",
    "    convert_missing=False,        # Replace missing values with NaN\n",
    "    preserve_dtypes=True,         # Preserve STATA datatypes\n",
    "    columns=['var1', 'var2'],     # Only read specific columns\n",
    "    order_categoricals=True       # Order converted categorical data\n",
    ")\n",
    "df_stata.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading STATA Files in Chunks\n",
    "\n",
    "For large STATA files, you can read the data in chunks to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of reading a STATA file in chunks (commented out as it requires a .dta file)\n",
    "\"\"\"\n",
    "# Read a STATA file in chunks of 10,000 lines\n",
    "itr = pd.read_stata('filename.dta', chunksize=10000)\n",
    "\n",
    "# Process each chunk\n",
    "for i, chunk in enumerate(itr):\n",
    "    print(f\"Processing chunk {i}, shape: {chunk.shape}\")\n",
    "    # Do something with the chunk\n",
    "    # For example, calculate summary statistics\n",
    "    print(chunk.describe())\n",
    "    \n",
    "    # Only process the first 3 chunks for demonstration\n",
    "    if i >= 2:\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to STATA Files\n",
    "\n",
    "You can also write pandas DataFrames to STATA files using the `to_stata()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, 6),\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'income': [50000, 60000, 75000, 90000, 85000],\n",
    "    'date': pd.date_range('2020-01-01', periods=5)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to STATA file\n",
    "stata_file = 'sample.dta'\n",
    "df.to_stata(stata_file)\n",
    "print(f\"Data written to {stata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Advanced Data Manipulation with pandas.concat\n",
    "\n",
    "The `pandas.concat()` function is a powerful tool for combining pandas objects along a particular axis with optional set logic along the other axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Concatenation\n",
    "\n",
    "Let's start with basic examples of concatenating DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\n",
    "df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate vertically (along axis=0, the default)\n",
    "result = pd.concat([df1, df2])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames with Different Columns\n",
    "\n",
    "When concatenating DataFrames with different columns, pandas will include all columns and fill missing values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with an additional column\n",
    "df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']], columns=['letter', 'number', 'animal'])\n",
    "\n",
    "print(\"DataFrame 3:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with different columns\n",
    "result = pd.concat([df1, df3], sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the join Parameter\n",
    "\n",
    "The `join` parameter determines how to handle columns when concatenating DataFrames with different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with join='inner' to keep only shared columns\n",
    "result = pd.concat([df1, df3], join=\"inner\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Horizontally\n",
    "\n",
    "You can concatenate DataFrames horizontally by setting `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame\n",
    "df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']], columns=['animal', 'name'])\n",
    "\n",
    "print(\"DataFrame 4:\")\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate horizontally\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Integrity\n",
    "\n",
    "You can use the `verify_integrity` parameter to check for duplicate index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with the same index\n",
    "df5 = pd.DataFrame([1], index=['a'])\n",
    "df6 = pd.DataFrame([2], index=['a'])\n",
    "\n",
    "print(\"DataFrame 5:\")\n",
    "print(df5)\n",
    "print(\"\\nDataFrame 6:\")\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate without verifying integrity\n",
    "result = pd.concat([df5, df6])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to concatenate with verify_integrity=True\n",
    "try:\n",
    "    result = pd.concat([df5, df6], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Dummy Variables with get_dummies\n",
    "\n",
    "The `pandas.get_dummies()` function is used to convert categorical variables into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage of get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with categorical variables\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F'],\n",
    "    'department': ['HR', 'IT', 'Finance', 'IT', 'HR'],\n",
    "    'age': [25, 30, 35, 40, 45]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gender to dummy variables\n",
    "dummies = pd.get_dummies(df['gender'])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical columns to dummy variables\n",
    "dummies_all = pd.get_dummies(df, columns=['gender', 'department'])\n",
    "dummies_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing Dummy Variable Names with Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom prefixes for dummy variable names\n",
    "dummies_prefix = pd.get_dummies(df, columns=['gender', 'department'], \n",
    "                               prefix=['Sex', 'Dept'])\n",
    "dummies_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the First Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first category to avoid the dummy variable trap\n",
    "dummies_drop_first = pd.get_dummies(df, columns=['gender', 'department'], \n",
    "                                   drop_first=True)\n",
    "dummies_drop_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with missing values\n",
    "df_missing = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'gender': ['F', 'M', np.nan, 'M', 'F'],\n",
    "    'department': ['HR', 'IT', 'Finance', np.nan, 'HR'],\n",
    "    'age': [25, 30, 35, 40, 45]\n",
    "})\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, missing values are ignored\n",
    "dummies_missing = pd.get_dummies(df_missing, columns=['gender', 'department'])\n",
    "dummies_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for missing values\n",
    "dummies_missing_na = pd.get_dummies(df_missing, columns=['gender', 'department'], \n",
    "                                   dummy_na=True)\n",
    "dummies_missing_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sparse Matrices for Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with many categories\n",
    "df_large = pd.DataFrame({\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], 1000)\n",
    "})\n",
    "\n",
    "# Use sparse=True for memory efficiency\n",
    "dummies_sparse = pd.get_dummies(df_large, sparse=True)\n",
    "\n",
    "# Compare memory usage\n",
    "dummies_dense = pd.get_dummies(df_large, sparse=False)\n",
    "\n",
    "print(f\"Sparse dummies memory usage: {dummies_sparse.memory_usage().sum() / 1024:.2f} KB\")\n",
    "print(f\"Dense dummies memory usage: {dummies_dense.memory_usage().sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "1. Working with STATA files, including:\n",
    "   - Reading STATA files with various options\n",
    "   - Reading STATA files in chunks\n",
    "   - Writing pandas DataFrames to STATA files\n",
    "\n",
    "2. Advanced data manipulation with pandas.concat, including:\n",
    "   - Basic concatenation\n",
    "   - Concatenating DataFrames with different columns\n",
    "   - Using the join parameter\n",
    "   - Concatenating horizontally\n",
    "   - Verifying integrity\n",
    "\n",
    "3. Creating dummy variables with get_dummies, including:\n",
    "   - Basic usage\n",
    "   - Customizing dummy variable names with prefix\n",
    "   - Dropping the first category\n",
    "   - Handling missing values\n",
    "   - Using sparse matrices for efficiency\n",
    "\n",
    "These techniques are essential for data preparation and manipulation in data analysis and machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}