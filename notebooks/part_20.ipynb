{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 20: Advanced Merging and Data Transformation in Pandas\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "- Completing our exploration of merge_asof\n",
    "- Using get_dummies for one-hot encoding\n",
    "- Factorizing values\n",
    "\n",
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Completing our Exploration of merge_asof\n",
    "\n",
    "Let's continue with the trades and quotes example from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames for trades and quotes\n",
    "trades = pd.DataFrame({\n",
    "    'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.038',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.048']),\n",
    "    'ticker': ['MSFT', 'MSFT', 'GOOG', 'GOOG', 'AAPL'],\n",
    "    'price': [51.95, 51.95, 720.77, 720.92, 98.00],\n",
    "    'quantity': [75, 155, 100, 100, 100]\n",
    "}, columns=['time', 'ticker', 'price', 'quantity'])\n",
    "\n",
    "quotes = pd.DataFrame({\n",
    "    'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.023',\n",
    "                           '20160525 13:30:00.030',\n",
    "                           '20160525 13:30:00.041',\n",
    "                           '20160525 13:30:00.048',\n",
    "                           '20160525 13:30:00.049',\n",
    "                           '20160525 13:30:00.072',\n",
    "                           '20160525 13:30:00.075']),\n",
    "    'ticker': ['GOOG', 'MSFT', 'MSFT', 'MSFT', 'GOOG', 'AAPL', 'GOOG', 'MSFT'],\n",
    "    'bid': [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n",
    "    'ask': [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03]\n",
    "}, columns=['time', 'ticker', 'bid', 'ask'])\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Trades:\")\n",
    "display(trades)\n",
    "print(\"\\nQuotes:\")\n",
    "display(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we are taking the asof of the quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic asof merge\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify a tolerance, so we only asof within a certain time difference (e.g., 2ms) between the quote time and the trade time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof merge with tolerance\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker', tolerance=pd.Timedelta('2ms'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the direction parameter to control whether the merge should look for values forward, backward, or nearest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof merge with direction='forward'\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker', direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asof merge with direction='nearest'\n",
    "pd.merge_asof(trades, quotes, on='time', by='ticker', direction='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using get_dummies for One-Hot Encoding\n",
    "\n",
    "The `get_dummies()` function is used to convert categorical variables into dummy/indicator variables (also known as one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with categorical columns\n",
    "df = pd.DataFrame({\n",
    "    'A': ['a', 'b', 'a'],\n",
    "    'B': ['b', 'c', 'b'],\n",
    "    'C': [1, 2, 3]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to dummy/indicator variables\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Customizing Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a list to specify prefixes\n",
    "from_list = pd.get_dummies(df, prefix=['from_A', 'from_B'])\n",
    "from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a dictionary to specify prefixes\n",
    "from_dict = pd.get_dummies(df, prefix={'B': 'from_B', 'A': 'from_A'})\n",
    "from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dropping First Category\n",
    "\n",
    "Sometimes it will be useful to only keep k-1 levels of a categorical variable to avoid collinearity when feeding the result to statistical models. You can switch to this mode by turning on `drop_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample Series\n",
    "s = pd.Series(list('abcaa'))\n",
    "\n",
    "# Default behavior\n",
    "pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first category\n",
    "pd.get_dummies(s, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a column contains only one level, it will be omitted in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with one column having only one level\n",
    "df = pd.DataFrame({'A': list('aaaaa'), 'B': list('ababc')})\n",
    "\n",
    "# Default behavior\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first category\n",
    "pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Specifying Data Type\n",
    "\n",
    "By default, new columns will have `np.uint8` dtype. To choose another dtype, use the `dtype` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with mixed types\n",
    "df = pd.DataFrame({'A': list('abc'), 'B': [1.1, 2.2, 3.3]})\n",
    "\n",
    "# Specify boolean dtype for dummy variables\n",
    "pd.get_dummies(df, dtype=bool).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factorizing Values\n",
    "\n",
    "To encode 1-d values as an enumerated type, use `factorize()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with mixed types and missing values\n",
    "x = pd.Series(['A', 'A', np.nan, 'B', 3.14, np.inf])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize the Series\n",
    "labels, uniques = pd.factorize(x)\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(labels)\n",
    "print(\"\\nUniques:\")\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `factorize` is similar to `numpy.unique`, but differs in its handling of NaN values. With `factorize`, NaN values are assigned a code of -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize with sort=True\n",
    "labels, uniques = pd.factorize(x, sort=True)\n",
    "\n",
    "print(\"Labels with sort=True:\")\n",
    "print(labels)\n",
    "print(\"\\nUniques with sort=True:\")\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Using Categorical Data Type\n",
    "\n",
    "If you just want to handle one column as a categorical variable (like R's factor), you can use `pd.Categorical` or the `category` dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with a column to be treated as categorical\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'color': ['red', 'blue', 'red', 'green', 'blue']\n",
    "})\n",
    "\n",
    "# Method 1: Using pd.Categorical\n",
    "df['color_cat1'] = pd.Categorical(df['color'])\n",
    "\n",
    "# Method 2: Using astype('category')\n",
    "df['color_cat2'] = df['color'].astype('category')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical codes\n",
    "print(\"Categorical codes:\")\n",
    "print(df['color_cat1'].cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Practical Example: Pivot Table with Factorized Data\n",
    "\n",
    "Let's create a more complex example using factorized data in a pivot table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed([3, 1415])\n",
    "n = 20\n",
    "\n",
    "# Create column names\n",
    "cols = np.array(['key', 'row', 'item', 'col'])\n",
    "\n",
    "# Create a DataFrame with random data\n",
    "df = pd.DataFrame(dict(zip(cols, np.random.randint(5, size=(4, n)).T)))\n",
    "df['value'] = np.random.randn(n)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table\n",
    "pivot = pd.pivot_table(df, values='value', index=['row', 'item'],\n",
    "                      columns='col', aggfunc=np.sum)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "1. Advanced features of `merge_asof` for time-series data, including tolerance and direction parameters\n",
    "2. Using `get_dummies` for one-hot encoding categorical variables with various options like prefix customization and dropping first categories\n",
    "3. Using `factorize` to encode values as enumerated types\n",
    "4. Working with the `Categorical` data type in pandas\n",
    "\n",
    "These techniques are essential for data preprocessing and transformation in data analysis and machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
